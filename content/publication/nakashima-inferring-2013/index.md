---
title: "Inferring what the videographer wanted to capture"
date: 2013-09-01
publishDate: 2020-03-11T00:06:08.595391Z
authors: ["Yuta Nakashima", "Naokazu Yokoya"]
publication_types: ["1"]
abstract: "Detecting important regions in videos has been extensively studied for past decades for their wide variety of applications including video summarization and retargeting. Visual attention models draw much attention for this purpose, which find visually salient regions. However, visual attention models ignore intentionally captured regions (ICRs) derived from videographers' intentions, i.e., what the videographers wanted to capture in their videos. This paper proposes a Markov random field-based ICR model for finding them. Observing that a videographer's intention is embedded into camera motion together with objects' motion, our ICR model uses point trajectory-based features to distinguish ICRs from non-ICRs. It also leverages spatial and temporal consistency of ICRs to improve the performance. We have experimentally demonstrated our ICR model's performance and the difference between ICRs and visually salient regions."
featured: false
publication: "*Proc. 2013 IEEE International Conference on Image Processing (ICIP)*"
tags: ["Videos", "Visualization", "image motion analysis", "Cameras", "video signal processing", "Computer vision", "video summarization", "camera motion", "cameras", "capture intentions", "intention map", "intentionally captured regions", "Intentionally captured regions", "Markov processes", "Markov random field-based ICR model", "object detection", "object motion", "point trajectory-based features", "random processes", "region detection", "Support vector machines", "Trajectory", "Vectors", "video retargeting", "videographer intention", "visual attention model", "visual attention models", "visually salient regions"]
doi: "10.1109/ICIP.2013.6738040"
---

