---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "Video Summary"
summary: ""
authors: []
tags: ["video-summarization", "deep-learning"]
categories: []
date: 2020-03-10T15:53:32+09:00

# Optional external URL for project (replaces project detail page).
external_link: ""

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Custom links (optional).
#   Uncomment and edit lines below to show custom links.
# links:
# - name: Follow
#   url: https://twitter.com
#   icon_pack: fab
#   icon: twitter

url_code: ""
url_pdf: ""
url_slides: ""
url_video: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""
---

Video summarization has been one of research topics that require deep understanding of video content. We explore various methods for automatic video summarization and also the limitation of current datasets. 

### Publications

- Mayu Otani, Yuta Nakashima, Esa Rahtu, and Janne Heikkilä (2019). [Rethinking the evaluation of video summaries](http://openaccess.thecvf.com/content_CVPR_2019/papers/Otani_Rethinking_the_Evaluation_of_Video_Summaries_CVPR_2019_paper.pdf). 
Proc.~Computer Vision and Pattern Recognition (CVPR), pp. 7596-7604.
- Antonio Tejero-de-Pablos, Yuta Nakashima, Tomokazu Sato, Naokazu Yokoya, Marko Linna, and Esa Rahtu (2018). [Summarization of user-generated sports video by using deep action recognition features](https://doi.org/10.1109/TMM.2018.2794265),'' IEEE Transactions on Multimedia, vol. 20, no. 8, pp. 2000-2011.
- Mayu Otani, Yuta Nakashima, Esa Rahtu, Janne Heikkilä, and Naokazu Yokoya (2018). Linking videos and languages: Representations and their applications. 情報処理学会研究報告, CVIM-212-38, 16 pages.
- Mayu Otani, Yuta Nakashima, Esa Rahtu, and Janne Heikkilä (2018). Finding video parts with natural language. 情報処理学会研究報告, CVIM-211-7, 7 pages.
- Mayu Otani, Yuta Nakashima, Esa Rahtu, and Janne Heikkilä (2017). Fine-grained video retrieval for multi-clip video. Closing the Loop Between Vision and Language (CLVL) at ICCV.
- Mayu Otani, Yuta Nakashima, Esa Rahtu, and Janne Heikkilä (2017). Video question answering to find a desired video segment. Open Knowledge Base and Question Answering Workshop (OKBQA) at SIGIR.
- Mayu Otani, Yuta Nakashima, Tomokazu Sato, and Naokazu Yokoya (2017). [Video summarization using textual descriptions for authoring video blogs](https://doi.org/10.1007/s11042-016-4061-3). Multimedia Tools and Applications, vol. 76, no. 9, pp. 12097-12115.
- Mayu Otani, Yuta Nakashima, Esa Rahtu, Janne Heikkilä, and Naokazu Yokoya (2016). Video summarization using deep semantic features. Proc.~Asian Conference on Computer Vision, 16 pages.
- Mayu Otani, Yuta Nakashima, Esa Rahtu, Janne Heikkilä, and Naokazu Yokoya (2016). Learning joint representations of videos and sentences with web image search. Proc. Workshop on Web-scale Vision and Social Media with ECCV6, 16 pages.
- Antonio Tejero-de-Pablos, Yuta Nakashima, Tomokazu Sato, and Naokazu Yokoya (2016). Human action recognition-based video summarization for RGB-D personal sports video. Proc. IEEE International Conference on Multimedia and Expo (ICME), 6 pages.
- Mayu Otani, Yuta Nakashima, Tomokazu Sato, and Naokazu Yokoya (2015). Textual description-based video summarization for video blogs. Proc. IEEE International Conference on Multimedia and Expo (ICME), 6 pages.