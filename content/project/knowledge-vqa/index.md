---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: "Knowledge VQA"
summary: ""
authors: []
tags: ["deep-learning", "knowledge", "visual question answering"]
categories: []
date: 2020-03-10T15:40:43+09:00

# Optional external URL for project (replaces project detail page).
external_link: ""

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ""
  focal_point: ""
  preview_only: false

# Custom links (optional).
#   Uncomment and edit lines below to show custom links.
# links:
# - name: Follow
#   url: https://twitter.com
#   icon_pack: fab
#   icon: twitter

url_code: "https://github.com/noagarcia/knowit-rock"
url_pdf: ""
url_slides: ""
url_video: ""

# Slides (optional).
#   Associate this project with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
slides: ""
---

Visual question answering (VQA) with knowledge is a task that requires knowledge to answer questions on images/video. This additional requirement of knowledge poses an interesting challenge on top of the classic VQA tasks. Specifically, a system needs to explore external knowledge sources to answer the questions correctly, as well as understanding the visual content. 

We created [a dedicated dataset for our knowledge VQA task](https://knowit-vqa.github.io) and made it open to public, so that everyone can enjoy our new task. We have also publish several papers on this task. 


### Publications

- Noa Garcia, Mayu Otani, Chenhui Chu, and Yuta Nakashima (2019). [KnowIT VQA: Answering knowledge-based questions about videos](https://arxiv.org/abs/1910.10706). Proc. AAAI Conference on Artificial Intelligence, Feb. 2020.
- Zekun Yang, Noa Garcia, Chenhui Chu, Mayu Otani, Yuta Nakashima, and Haruo Takemura (2020). [BERT representations for video question answering](http://openaccess.thecvf.com/content_WACV_2020/html/Yang_BERT_representations_for_Video_Question_Answering_WACV_2020_paper.html). Proc.~IEEE Winter Conference on Applications of Computer Vision.
- Noa Garcia, Chenhui Chu, Mayu Otani, and Yuta Nakashima (2019). Video meets knowledge in visual question answering. MIRU.
- Zekun Yang, Noa Garcia, Chenhui Chu, Mayu Otani, Yuta Nakashima, and Haruo Takemura (2019).
Video question answering with BERT. MIRU.